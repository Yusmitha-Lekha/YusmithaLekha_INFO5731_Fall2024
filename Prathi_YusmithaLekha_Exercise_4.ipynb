{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Yusmitha-Lekha/YusmithaLekha_INFO5731_Fall2024/blob/main/Prathi_YusmithaLekha_Exercise_4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VdRwkJBn70nX"
      },
      "source": [
        "# **INFO5731 In-class Exercise 4**\n",
        "\n",
        "**This exercise will provide a valuable learning experience in working with text data and extracting features using various topic modeling algorithms. Key concepts such as Latent Dirichlet Allocation (LDA), Latent Semantic Analysis (LSA), lda2vec, and BERTopic.**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Please use the text corpus you collected in your last in-class-exercise for this exercise. Perform the following tasks***.\n",
        "\n",
        "**Expectations**:\n",
        "*   Students are expected to complete the exercise during lecture period to meet the active participation criteria of the course.\n",
        "*   Use the provided .*ipynb* document to write your code & respond to the questions. Avoid generating a new file.\n",
        "*   Write complete answers and run all the cells before submission.\n",
        "*   Make sure the submission is \"clean\"; *i.e.*, no unnecessary code cells.\n",
        "*   Once finished, allow shared rights from top right corner (*see Canvas for details*).\n",
        "\n",
        "**Total points**: 40\n",
        "\n",
        "**Deadline**: This in-class exercise is due at the end of the day tomorrow, at 11:59 PM.\n",
        "\n",
        "**Late submissions will have a penalty of 10% of the marks for each day of late submission, and no requests will be answered. Manage your time accordingly.**\n"
      ],
      "metadata": {
        "id": "TU-pLW33lpcS"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ARqm7u6B70ne"
      },
      "source": [
        "## Question 1 (10 Points)\n",
        "\n",
        "**Generate K topics by using LDA, the number of topics K should be decided by the coherence score, then summarize what are the topics.**\n",
        "\n",
        "You may refer the code here: https://www.machinelearningplus.com/nlp/topic-modeling-gensim-python/"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Write your code here\n",
        "from gensim.corpora import Dictionary\n",
        "from gensim.models import LdaModel\n",
        "from gensim.models.coherencemodel import CoherenceModel\n",
        "import pandas as pd\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "# Ensure nltk stopwords are downloaded\n",
        "nltk.download('stopwords')\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "# Sample data\n",
        "data = pd.DataFrame({\n",
        "    'text': [\n",
        "        \"I bought this phone two weeks ago, and I have been extremely satisfied with its performance. The battery lasts all day, and the camera quality is outstanding. Highly recommend!\",\n",
        "    \"Terrible laptop. It overheats constantly, and the battery dies in just a couple of hours. I regret purchasing this product.\",\n",
        "    \"This vacuum cleaner has made my life so much easier. It's lightweight, powerful, and very easy to maneuver. I love how clean my house feels after using it.\",\n",
        "    \"The sound quality of these headphones is amazing. However, after just two months, one side stopped working. I'm disappointed with the durability.\",\n",
        "    \"I’ve tried a lot of fitness trackers, and this one is by far the best. It’s comfortable to wear, the tracking is accurate, and I love the sleep monitoring feature.\",\n",
        "    \"This blender is a waste of money. It struggles with basic tasks like blending frozen fruit and constantly overheats. Definitely avoid this product.\",\n",
        "    \"Fantastic service! The customer support team was responsive and helped me resolve my issue quickly. I will continue to shop with this company.\",\n",
        "    \"The quality of this TV is top-notch. The picture is crystal clear, and the smart features are easy to use. It's the best TV I’ve ever owned.\",\n",
        "    \"Worst purchase ever. The shoes fell apart after just a few days of light use. Poorly made and not worth the money.\",\n",
        "    \"The camera takes great photos, but the app is clunky and hard to navigate. I would give it 5 stars for the camera, but the software brings it down to a 3.\",\n",
        "    \"I love this coffee maker. It’s quick, easy to use, and makes the best cup of coffee I’ve ever had at home. I can’t start my day without it.\",\n",
        "    \"The washing machine is too loud and doesn't clean clothes as well as my old one. It's not worth the high price tag.\",\n",
        "    \"The tablet is great for reading and light browsing, but it slows down when I try to use it for anything more demanding. Good for basic tasks, but not a powerful device.\",\n",
        "    \"I purchased this sofa for my living room, and it fits perfectly. The material feels durable, and it’s very comfortable to sit on. Highly satisfied with this purchase.\",\n",
        "    \"The smartwatch looks nice, but the battery life is terrible. It barely lasts through the day without needing a charge. I wouldn't recommend it.\",\n",
        "    \"This lawnmower works great for my small yard. It’s easy to push and cuts the grass evenly. I’m happy with my purchase so far.\",\n",
        "    \"The wireless mouse stopped working after just a week of use. I had higher expectations for this brand, but unfortunately, the quality is subpar.\",\n",
        "    \"I'm thrilled with my new gaming chair. It’s extremely comfortable, and the adjustable settings let me customize it to my preferences. Definitely worth the investment.\",\n",
        "    \"This printer is the worst. It constantly jams, the ink cartridges are expensive, and the print quality is terrible. Do not buy!\",\n",
        "    \"I’ve been using this air purifier for a month, and I can already notice a difference in the air quality. My allergies have improved, and it runs quietly in the background.\"\n",
        "    ]\n",
        "})\n",
        "\n",
        "# Preprocess text: lowercasing, removing stopwords\n",
        "data['processed'] = data['text'].apply(lambda x: ' '.join([word for word in x.lower().split() if word not in stop_words]))\n",
        "data['tokenized'] = data['processed'].apply(lambda x: x.split())\n",
        "\n",
        "# Create dictionary and corpus\n",
        "dictionary = Dictionary(data['tokenized'])\n",
        "corpus = [dictionary.doc2bow(text) for text in data['tokenized']]\n",
        "\n",
        "# Determine the best number of topics using coherence score\n",
        "coherence_scores = []\n",
        "models = []\n",
        "for k in range(2, 8):  # Trying 2 to 5 topics\n",
        "    lda_model = LdaModel(corpus, num_topics=k, id2word=dictionary, random_state=100, passes=10)\n",
        "    coherence_model = CoherenceModel(model=lda_model, texts=data['tokenized'], dictionary=dictionary, coherence='c_v')\n",
        "    coherence_score = coherence_model.get_coherence()\n",
        "    coherence_scores.append((k, coherence_score))\n",
        "    models.append(lda_model)\n",
        "\n",
        "# Find best model based on coherence score\n",
        "best_k = max(coherence_scores, key=lambda x: x[1])[0]\n",
        "best_lda_model = models[best_k - 2]\n",
        "\n",
        "# Display topics\n",
        "print(f\"Best Number of Topics: {best_k}\")\n",
        "for idx, topic in best_lda_model.show_topics(formatted=False):\n",
        "    print(f\"Topic {idx + 1}: {[word for word, prob in topic]}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_EUhs-Wp1ZA9",
        "outputId": "682e27dd-1e1e-4288-f7b5-2a0c8166c1d0"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Number of Topics: 2\n",
            "Topic 1: ['quality', 'battery', 'lasts', 'basic', 'terrible.', 'constantly', 'satisfied', 'it’s', 'highly', 'comfortable']\n",
            "Topic 2: ['easy', 'i’ve', 'it’s', 'worth', 'use.', 'great', 'air', 'tv', \"i'm\", 'quality']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dEUjBE6C70nf"
      },
      "source": [
        "## Question 2 (10 Points)\n",
        "\n",
        "**Generate K topics by using LSA, the number of topics K should be decided by the coherence score, then summarize what are the topics.**\n",
        "\n",
        "You may refer the code here: https://www.datacamp.com/community/tutorials/discovering-hidden-topics-python"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Write your code here\n",
        "from sklearn.decomposition import TruncatedSVD\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# Apply TF-IDF to convert text data into a word frequency matrix\n",
        "vectorizer = TfidfVectorizer(stop_words='english')\n",
        "X = vectorizer.fit_transform(data['processed'])\n",
        "\n",
        "# Set up and apply LSA to reduce data to a specified number of topics (e.g., 2 topics)\n",
        "n_topics = 2\n",
        "lsa = TruncatedSVD(n_components=n_topics, random_state=100)\n",
        "lsa.fit(X)\n",
        "\n",
        "# Output the most relevant words for each topic identified\n",
        "terms = vectorizer.get_feature_names_out()\n",
        "for idx, topic in enumerate(lsa.components_):\n",
        "    print(f\"Topic {idx + 1}: \", [terms[i] for i in topic.argsort()[-10:]])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6G76oqja26gc",
        "outputId": "599a933c-4978-4e32-ee3f-cc8e46a76e37"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Topic 1:  ['coffee', 'best', 'constantly', 've', 'easy', 'terrible', 'day', 'battery', 'use', 'quality']\n",
            "Topic 2:  ['laptop', 'hours', 'dies', 'recommend', 'lasts', 'product', 'overheats', 'constantly', 'battery', 'terrible']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7oSK4soH70nf"
      },
      "source": [
        "## Question 3 (10 points):\n",
        "**Generate K topics by using lda2vec, the number of topics K should be decided by the coherence score, then summarize what are the topics.**\n",
        "\n",
        "You may refer the code here: https://nbviewer.org/github/cemoody/lda2vec/blob/master/examples/twenty_newsgroups/lda2vec/lda2vec.ipynb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "2CRuXfV570ng"
      },
      "outputs": [],
      "source": [
        "# Write your code here\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7nZGAOwl70ng"
      },
      "source": [
        "## Question 4 (10 points):\n",
        "**Generate K topics by using BERTopic, the number of topics K should be decided by the coherence score, then summarize what are the topics.**\n",
        "\n",
        "You may refer the code here: https://colab.research.google.com/drive/1FieRA9fLdkQEGDIMYl0I3MCjSUKVF8C-?usp=sharing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "b4HoWK-i70ng",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "36572514-134b-4cf9-aa68-cfb601543bf4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Topic 1: [('the', 0.2000459536807333), ('and', 0.13640410885445992), ('this', 0.10733112202710283), ('is', 0.10208274543782703), ('it', 0.10208274543782703), ('to', 0.08546675583397369), ('my', 0.08546675583397369), ('its', 0.07352527177588986), ('for', 0.06723848059743669), ('of', 0.06723848059743669)]\n"
          ]
        }
      ],
      "source": [
        "# Import BERTopic library\n",
        "from bertopic import BERTopic\n",
        "\n",
        "# Set up and train the BERTopic model on the text data\n",
        "model = BERTopic()\n",
        "topics, probs = model.fit_transform(data['text'])\n",
        "\n",
        "# Output the topics generated by the model\n",
        "for idx, topic in enumerate(model.get_topics().values()):\n",
        "    print(f\"Topic {idx + 1}: {topic[:10]}\")  # Show the top 10 words for each identified topic\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Question 3 (Alternative) - (10 points)**\n",
        "\n",
        "If you are unable to do the topic modeling using lda2vec, do the alternate question.\n",
        "\n",
        "Provide atleast 3 visualization for the topics generated by the BERTopic or LDA model. Explain each of the visualization in detail."
      ],
      "metadata": {
        "id": "Wslk2SYHML8t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Write your code here\n",
        "# Then Explain the visualization\n",
        "# Repeat for the other 2 visualizations as well."
      ],
      "metadata": {
        "id": "eKZHcPjpNEDx"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyLDAvis\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XF5JmBZn31rv",
        "outputId": "f5ef2b8f-e430-4ddc-8a93-d10b7bd8e86b"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyLDAvis in /usr/local/lib/python3.10/dist-packages (3.4.1)\n",
            "Requirement already satisfied: numpy>=1.24.2 in /usr/local/lib/python3.10/dist-packages (from pyLDAvis) (1.26.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from pyLDAvis) (1.13.1)\n",
            "Requirement already satisfied: pandas>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from pyLDAvis) (2.2.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from pyLDAvis) (1.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from pyLDAvis) (3.1.4)\n",
            "Requirement already satisfied: numexpr in /usr/local/lib/python3.10/dist-packages (from pyLDAvis) (2.10.1)\n",
            "Requirement already satisfied: funcy in /usr/local/lib/python3.10/dist-packages (from pyLDAvis) (2.0)\n",
            "Requirement already satisfied: scikit-learn>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from pyLDAvis) (1.5.2)\n",
            "Requirement already satisfied: gensim in /usr/local/lib/python3.10/dist-packages (from pyLDAvis) (4.3.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from pyLDAvis) (75.1.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=2.0.0->pyLDAvis) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=2.0.0->pyLDAvis) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=2.0.0->pyLDAvis) (2024.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.0.0->pyLDAvis) (3.5.0)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from gensim->pyLDAvis) (7.0.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->pyLDAvis) (3.0.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas>=2.0.0->pyLDAvis) (1.16.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open>=1.8.1->gensim->pyLDAvis) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pyLDAvis.gensim_models as gensimvis\n",
        "import pyLDAvis\n",
        "\n",
        "# Visualize LDA topics\n",
        "lda_display = gensimvis.prepare(best_lda_model, corpus, dictionary)\n",
        "pyLDAvis.display(lda_display)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 882
        },
        "id": "1sE3Oxhx3tTB",
        "outputId": "2e7ed02b-057b-48a7-b200-55a38b660ba6"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.4.0/pyLDAvis/js/ldavis.v1.0.0.css\">\n",
              "\n",
              "\n",
              "<div id=\"ldavis_el144101355916925437929948664911\" style=\"background-color:white;\"></div>\n",
              "<script type=\"text/javascript\">\n",
              "\n",
              "var ldavis_el144101355916925437929948664911_data = {\"mdsDat\": {\"x\": [0.061192699215610935, -0.061192699215610935], \"y\": [0.0, 0.0], \"topics\": [1, 2], \"cluster\": [1, 1], \"Freq\": [51.560120174454326, 48.439879825545674]}, \"tinfo\": {\"Term\": [\"easy\", \"lasts\", \"basic\", \"terrible.\", \"constantly\", \"satisfied\", \"highly\", \"comfortable\", \"air\", \"tv\", \"i'm\", \"purchase\", \"best\", \"ever\", \"using\", \"made\", \"coffee\", \"i\\u2019ve\", \"tasks,\", \"reading\", \"demanding.\", \"powerful\", \"slows\", \"good\", \"tablet\", \"try\", \"anything\", \"browsing,\", \"device.\", \"use\", \"easy\", \"air\", \"tv\", \"i'm\", \"purchase\", \"best\", \"ever\", \"using\", \"made\", \"coffee\", \"allergies\", \"difference\", \"quietly\", \"notice\", \"quality.\", \"month,\", \"improved,\", \"runs\", \"purifier\", \"background.\", \"headphones\", \"disappointed\", \"clear,\", \"durability.\", \"already\", \"months,\", \"however,\", \"owned.\", \"sound\", \"amazing.\", \"i\\u2019ve\", \"it\\u2019s\", \"worth\", \"use.\", \"great\", \"love\", \"it.\", \"quality\", \"one\", \"stopped\", \"definitely\", \"extremely\", \"money.\", \"lasts\", \"basic\", \"terrible.\", \"constantly\", \"satisfied\", \"highly\", \"comfortable\", \"tasks,\", \"reading\", \"demanding.\", \"powerful\", \"slows\", \"good\", \"tablet\", \"try\", \"anything\", \"browsing,\", \"device.\", \"use\", \"recommend!\", \"bought\", \"charge.\", \"performance.\", \"recommend\", \"looks\", \"barely\", \"smartwatch\", \"outstanding.\", \"weeks\", \"needing\", \"quality\", \"battery\", \"it\\u2019s\", \"life\", \"feels\", \"clean\", \"it.\", \"love\", \"day\", \"without\", \"light\", \"product.\", \"camera\", \"two\", \"money.\", \"extremely\", \"definitely\", \"stopped\"], \"Freq\": [2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.515272521901223, 1.4035333545030897, 1.402774729972256, 1.402536899994087, 1.4006529847381095, 1.3984289530503675, 1.3973001689354154, 1.394952331512857, 1.3933826816040604, 1.3929176415527407, 0.842023134015682, 0.8419027518028779, 0.84189304017921, 0.8418745950810207, 0.8418707523522312, 0.841848674128641, 0.8418277137897894, 0.841825128681331, 0.8418147882474976, 0.8418025613831674, 0.841682039434771, 0.8416786159127586, 0.841671419529753, 0.841649900248532, 0.8416406776994373, 0.8416281014961264, 0.8416181104012739, 0.8416046259166127, 0.8416014119979888, 0.8415957527064989, 1.9813214440104086, 1.9707285079616115, 1.4132730650250362, 1.4132572749031014, 1.4075475388643466, 1.3843693166911164, 1.3741102089724282, 1.402457669913228, 0.8459293027640571, 0.843960568003527, 0.8436001200430765, 0.842629796089842, 0.8418262465660697, 1.3588409459870914, 1.3582235395471831, 1.3573913602100411, 1.3573803327507699, 1.3569992290095294, 1.3567727722566394, 1.3548427043256313, 0.8153283291413986, 0.8153148073758637, 0.8153075213759882, 0.815293080655514, 0.8152905863492502, 0.8152852038988917, 0.815282709592628, 0.8152815937187732, 0.8152778522593777, 0.8152707631784176, 0.8152678750343227, 0.8152617705479405, 0.8151549092164319, 0.815122155036811, 0.8150458161372135, 0.8150154249845792, 0.8150122742819303, 0.8150069574712103, 0.8150042006063926, 0.8149971115254325, 0.8149967833272399, 0.8149835241202591, 0.8149833928409821, 1.9071590407687489, 1.3722018944076029, 1.356893155353683, 0.8480285529794414, 0.8428060007803277, 0.8412775817974163, 0.8462035084700633, 0.8362697368558979, 0.824802229448101, 0.8247268751430814, 0.8191070062120132, 0.8185070599159509, 0.8183367250539945, 0.8177703862528538, 0.8174206582588254, 0.8166426316234615, 0.8157028689187872, 0.8153537316815054], \"Total\": [2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.800687552964722, 1.6770595537290487, 1.6770352398343253, 1.6770276080684419, 1.6769677691371743, 1.6768970786108623, 1.6768612929367068, 1.6767867202951523, 1.6767367921171634, 1.6767221384455409, 1.1150668654886178, 1.1150628951747268, 1.1150625536094574, 1.115061978902855, 1.115061877633461, 1.11506109947257, 1.1150605202414787, 1.1150603637996455, 1.1150601154602344, 1.1150597529605666, 1.1150559054696374, 1.1150557311097316, 1.1150555417581378, 1.1150547810125986, 1.115054452634523, 1.1150541346337057, 1.115053841795444, 1.1150533539592098, 1.1150532251035963, 1.1150531123615612, 2.783755063083695, 3.3276216633152944, 2.22155438821469, 2.2215539577681684, 2.2213732454007715, 2.220639053547014, 2.2203137174424916, 3.309616710681977, 1.6593768593429752, 1.6593142996850325, 1.6593029889618638, 1.6592724277133035, 1.659246904824895, 1.6415484593939702, 1.641568614061079, 1.6415954767448189, 1.641596012405814, 1.6416085438282055, 1.6416158647213066, 1.641678758209151, 1.0973235927671525, 1.097324044560852, 1.097324251882116, 1.0973247628700227, 1.097324748870523, 1.0973249558438583, 1.0973251339807981, 1.0973250311899876, 1.0973252372610758, 1.097325519232612, 1.0973254782012112, 1.0973256792834334, 1.0973292964046215, 1.0973303407713986, 1.0973327778119848, 1.0973338097006788, 1.0973337855819087, 1.0973340232609843, 1.0973341135088606, 1.0973343256126005, 1.097334399154236, 1.0973348165683556, 1.0973347376899258, 3.309616710681977, 2.203103193157467, 3.3276216633152944, 1.6582440234489133, 1.6584155445854503, 1.6584653692502642, 2.2203137174424916, 2.220639053547014, 1.6590050610382692, 1.6590076791937773, 1.6591916582229076, 1.6592112296755008, 1.6592170315276937, 1.6592354163127152, 1.659246904824895, 1.6592724277133035, 1.6593029889618638, 1.6593142996850325], \"Category\": [\"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\"], \"logprob\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, -4.0885, -4.6719, -4.6724, -4.6726, -4.674, -4.6756, -4.6764, -4.678, -4.6792, -4.6795, -5.1828, -5.183, -5.183, -5.183, -5.183, -5.1831, -5.1831, -5.1831, -5.1831, -5.1831, -5.1833, -5.1833, -5.1833, -5.1833, -5.1833, -5.1833, -5.1833, -5.1833, -5.1834, -5.1834, -4.3271, -4.3325, -4.665, -4.665, -4.6691, -4.6857, -4.6931, -4.6727, -5.1782, -5.1806, -5.181, -5.1821, -5.1831, -4.6418, -4.6423, -4.6429, -4.6429, -4.6432, -4.6434, -4.6448, -5.1526, -5.1527, -5.1527, -5.1527, -5.1527, -5.1527, -5.1527, -5.1527, -5.1527, -5.1527, -5.1527, -5.1527, -5.1529, -5.1529, -5.153, -5.153, -5.153, -5.153, -5.153, -5.153, -5.153, -5.1531, -5.1531, -4.3029, -4.6321, -4.6433, -5.1133, -5.1195, -5.1213, -5.1155, -5.1273, -5.1411, -5.1412, -5.148, -5.1487, -5.149, -5.1497, -5.1501, -5.151, -5.1522, -5.1526], \"loglift\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, 0.5549, 0.4844, 0.4838, 0.4837, 0.4824, 0.4808, 0.48, 0.4784, 0.4773, 0.477, 0.3816, 0.3814, 0.3814, 0.3814, 0.3814, 0.3814, 0.3813, 0.3813, 0.3813, 0.3813, 0.3812, 0.3812, 0.3812, 0.3811, 0.3811, 0.3811, 0.3811, 0.3811, 0.3811, 0.3811, 0.3224, 0.1386, 0.2101, 0.2101, 0.2061, 0.1899, 0.1826, -0.1962, -0.0113, -0.0136, -0.0141, -0.0152, -0.0161, 0.5358, 0.5354, 0.5347, 0.5347, 0.5344, 0.5343, 0.5328, 0.4278, 0.4278, 0.4278, 0.4278, 0.4278, 0.4278, 0.4278, 0.4277, 0.4277, 0.4277, 0.4277, 0.4277, 0.4276, 0.4275, 0.4275, 0.4274, 0.4274, 0.4274, 0.4274, 0.4274, 0.4274, 0.4274, 0.4274, 0.1736, 0.2514, -0.1722, 0.0542, 0.048, 0.0461, -0.2398, -0.2518, 0.026, 0.0259, 0.019, 0.0182, 0.018, 0.0173, 0.0169, 0.0159, 0.0147, 0.0143]}, \"token.table\": {\"Topic\": [1, 1, 1, 1, 2, 1, 2, 2, 1, 2, 1, 2, 2, 1, 2, 2, 1, 2, 1, 1, 2, 2, 1, 2, 1, 2, 2, 2, 1, 1, 1, 1, 1, 1, 2, 1, 2, 2, 1, 2, 1, 2, 1, 1, 1, 1, 2, 1, 2, 1, 2, 2, 1, 2, 1, 2, 2, 1, 2, 1, 1, 2, 1, 1, 2, 1, 1, 2, 2, 1, 2, 2, 1, 2, 1, 1, 1, 2, 1, 1, 2, 2, 2, 1, 2, 2, 2, 1, 1, 2, 2, 2, 2, 2, 1, 1, 2, 2, 1, 2, 1, 2, 1, 2, 1, 2], \"Freq\": [0.5962817466895772, 0.8968072058726309, 0.8968171891850792, 0.8968182671425478, 0.9113068450845079, 0.8968129262534368, 0.9112994735964028, 0.6091734402292808, 0.4539052020376809, 0.4539052020376809, 0.5963395206272276, 0.9113026067401203, 0.9113066109128, 0.6026939098372612, 0.6026939098372612, 0.9113005828495705, 0.6029670673509848, 0.6029670673509848, 0.8968163132244277, 0.5964017394838492, 0.6091325693285234, 0.6091632730847503, 0.6027709158247905, 0.6027709158247905, 0.6026626882807256, 0.6026626882807256, 0.9113076634229247, 0.9113066449885482, 0.8968103990612146, 0.8968161609328484, 0.8968169250768868, 1.0711655417700172, 0.5963522470297399, 0.6026737884014213, 0.6026737884014213, 0.6029851826129424, 0.6029851826129424, 0.9113070787959853, 0.45017198351085025, 0.45017198351085025, 0.8968160206988202, 0.6091559063787239, 0.8968176804716569, 0.5962931052469522, 0.8968123091502145, 0.45038680441603, 0.45038680441603, 0.601029865278437, 0.3005149326392185, 0.718454014335768, 0.359227007167884, 0.6091809195624854, 0.6030475526274723, 0.6030475526274723, 0.602703126576142, 0.602703126576142, 0.9112995485442678, 0.45032082021736297, 0.45032082021736297, 0.5963965272911624, 0.6026830588576767, 0.6026830588576767, 0.8968118432909241, 0.8968174449471901, 0.9112989552350891, 0.896811135990783, 0.6026358595816184, 0.6026358595816184, 0.9112992363774837, 0.8968180728297073, 0.91129972589906, 0.9113072390570387, 0.6026960173091248, 0.6026960173091248, 0.596314382663726, 0.8968126347046822, 0.3021497917787407, 0.6042995835574814, 0.8968112174387476, 0.8968106737716195, 0.911307835599464, 0.9112997459289077, 0.9113034740587724, 0.896812434972068, 0.6091586229613642, 0.9113072506833557, 0.9112992974513374, 0.8968181764660543, 0.6026585802278795, 0.6026585802278795, 0.9113069308567381, 0.9113082108061408, 0.60916347185784, 0.9113070162224914, 0.5962903916668979, 0.6026872318228835, 0.6026872318228835, 0.9113064779938549, 0.45013536425855094, 0.45013536425855094, 0.5963787689253511, 0.9112988897292567, 0.6027699645645804, 0.6027699645645804, 0.450135277040699, 0.450135277040699], \"Term\": [\"air\", \"allergies\", \"already\", \"amazing.\", \"anything\", \"background.\", \"barely\", \"basic\", \"battery\", \"battery\", \"best\", \"bought\", \"browsing,\", \"camera\", \"camera\", \"charge.\", \"clean\", \"clean\", \"clear,\", \"coffee\", \"comfortable\", \"constantly\", \"day\", \"day\", \"definitely\", \"definitely\", \"demanding.\", \"device.\", \"difference\", \"disappointed\", \"durability.\", \"easy\", \"ever\", \"extremely\", \"extremely\", \"feels\", \"feels\", \"good\", \"great\", \"great\", \"headphones\", \"highly\", \"however,\", \"i'm\", \"improved,\", \"it.\", \"it.\", \"it\\u2019s\", \"it\\u2019s\", \"i\\u2019ve\", \"i\\u2019ve\", \"lasts\", \"life\", \"life\", \"light\", \"light\", \"looks\", \"love\", \"love\", \"made\", \"money.\", \"money.\", \"month,\", \"months,\", \"needing\", \"notice\", \"one\", \"one\", \"outstanding.\", \"owned.\", \"performance.\", \"powerful\", \"product.\", \"product.\", \"purchase\", \"purifier\", \"quality\", \"quality\", \"quality.\", \"quietly\", \"reading\", \"recommend\", \"recommend!\", \"runs\", \"satisfied\", \"slows\", \"smartwatch\", \"sound\", \"stopped\", \"stopped\", \"tablet\", \"tasks,\", \"terrible.\", \"try\", \"tv\", \"two\", \"two\", \"use\", \"use.\", \"use.\", \"using\", \"weeks\", \"without\", \"without\", \"worth\", \"worth\"]}, \"R\": 30, \"lambda.step\": 0.01, \"plot.opts\": {\"xlab\": \"PC1\", \"ylab\": \"PC2\"}, \"topic.order\": [2, 1]};\n",
              "\n",
              "function LDAvis_load_lib(url, callback){\n",
              "  var s = document.createElement('script');\n",
              "  s.src = url;\n",
              "  s.async = true;\n",
              "  s.onreadystatechange = s.onload = callback;\n",
              "  s.onerror = function(){console.warn(\"failed to load library \" + url);};\n",
              "  document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
              "}\n",
              "\n",
              "if(typeof(LDAvis) !== \"undefined\"){\n",
              "   // already loaded: just create the visualization\n",
              "   !function(LDAvis){\n",
              "       new LDAvis(\"#\" + \"ldavis_el144101355916925437929948664911\", ldavis_el144101355916925437929948664911_data);\n",
              "   }(LDAvis);\n",
              "}else if(typeof define === \"function\" && define.amd){\n",
              "   // require.js is available: use it to load d3/LDAvis\n",
              "   require.config({paths: {d3: \"https://d3js.org/d3.v5\"}});\n",
              "   require([\"d3\"], function(d3){\n",
              "      window.d3 = d3;\n",
              "      LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.4.0/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",
              "        new LDAvis(\"#\" + \"ldavis_el144101355916925437929948664911\", ldavis_el144101355916925437929948664911_data);\n",
              "      });\n",
              "    });\n",
              "}else{\n",
              "    // require.js not available: dynamically load d3 & LDAvis\n",
              "    LDAvis_load_lib(\"https://d3js.org/d3.v5.js\", function(){\n",
              "         LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.4.0/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",
              "                 new LDAvis(\"#\" + \"ldavis_el144101355916925437929948664911\", ldavis_el144101355916925437929948664911_data);\n",
              "            })\n",
              "         });\n",
              "}\n",
              "</script>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "LDA (Latent Dirichlet Allocation): LDA is effective for generating distinct and interpretable topics by analyzing word distributions across documents. Its use of coherence scores to evaluate the quality of topic separation makes it highly reliable for applications requiring clear and non-overlapping topics. This model is especially suitable for scenarios where specific, well-defined topics are essential, as it helps differentiate distinct themes within a text corpus."
      ],
      "metadata": {
        "id": "Ok-iQ8j941AS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.decomposition import TruncatedSVD\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from bertopic import BERTopic\n",
        "\n",
        "# Sample reviews data in a DataFrame\n",
        "reviews_data = pd.DataFrame({\n",
        "    'content': [\n",
        "         \"I bought this phone two weeks ago, and I have been extremely satisfied with its performance. The battery lasts all day, and the camera quality is outstanding. Highly recommend!\",\n",
        "         \"Terrible laptop. It overheats constantly, and the battery dies in just a couple of hours. I regret purchasing this product.\",\n",
        "         \"This vacuum cleaner has made my life so much easier. It's lightweight, powerful, and very easy to maneuver. I love how clean my house feels after using it.\",\n",
        "         \"The sound quality of these headphones is amazing. However, after just two months, one side stopped working. I'm disappointed with the durability.\",\n",
        "         \"I’ve tried a lot of fitness trackers, and this one is by far the best. It’s comfortable to wear, the tracking is accurate, and I love the sleep monitoring feature.\",\n",
        "         \"This blender is a waste of money. It struggles with basic tasks like blending frozen fruit and constantly overheats. Definitely avoid this product.\",\n",
        "         \"Fantastic service! The customer support team was responsive and helped me resolve my issue quickly. I will continue to shop with this company.\",\n",
        "         \"The quality of this TV is top-notch. The picture is crystal clear, and the smart features are easy to use. It's the best TV I’ve ever owned.\",\n",
        "         \"Worst purchase ever. The shoes fell apart after just a few days of light use. Poorly made and not worth the money.\",\n",
        "         \"The camera takes great photos, but the app is clunky and hard to navigate. I would give it 5 stars for the camera, but the software brings it down to a 3.\",\n",
        "         \"I love this coffee maker. It’s quick, easy to use, and makes the best cup of coffee I’ve ever had at home. I can’t start my day without it.\",\n",
        "         \"The washing machine is too loud and doesn't clean clothes as well as my old one. It's not worth the high price tag.\",\n",
        "         \"The tablet is great for reading and light browsing, but it slows down when I try to use it for anything more demanding. Good for basic tasks, but not a powerful device.\",\n",
        "         \"I purchased this sofa for my living room, and it fits perfectly. The material feels durable, and it’s very comfortable to sit on. Highly satisfied with this purchase.\",\n",
        "         \"The smartwatch looks nice, but the battery life is terrible. It barely lasts through the day without needing a charge. I wouldn't recommend it.\",\n",
        "         \"This lawnmower works great for my small yard. It’s easy to push and cuts the grass evenly. I’m happy with my purchase so far.\",\n",
        "         \"The wireless mouse stopped working after just a week of use. I had higher expectations for this brand, but unfortunately, the quality is subpar.\",\n",
        "         \"I'm thrilled with my new gaming chair. It’s extremely comfortable, and the adjustable settings let me customize it to my preferences. Definitely worth the investment.\",\n",
        "         \"This printer is the worst. It constantly jams, the ink cartridges are expensive, and the print quality is terrible. Do not buy!\",\n",
        "         \"I’ve been using this air purifier for a month, and I can already notice a difference in the air quality. My allergies have improved, and it runs quietly in the background.\"\n",
        "    ]\n",
        "})\n",
        "\n",
        "# Lowercase text for consistent processing\n",
        "reviews_data['processed_text'] = reviews_data['content'].apply(lambda x: x.lower())\n",
        "\n",
        "print(\"LSA Model: Summarizing broader patterns and possible term overlap.\\n\")\n",
        "\n",
        "# Initialize TF-IDF Vectorizer and transform the text data\n",
        "tfidf_vectorizer = TfidfVectorizer(stop_words='english')\n",
        "tfidf_matrix = tfidf_vectorizer.fit_transform(reviews_data['processed_text'])\n",
        "\n",
        "# Set the number of topics for LSA\n",
        "num_topics = 3\n",
        "lsa_model = TruncatedSVD(n_components=num_topics, random_state=100)\n",
        "lsa_model.fit(tfidf_matrix)\n",
        "\n",
        "# Display the most relevant terms for each LSA topic\n",
        "feature_names = tfidf_vectorizer.get_feature_names_out()\n",
        "for idx, topic in enumerate(lsa_model.components_):\n",
        "    print(f\"LSA Topic {idx + 1}: \", [feature_names[i] for i in topic.argsort()[-10:]])\n",
        "\n",
        "# =================== BERTopic Analysis ===================\n",
        "print(\"\\nBERTopic Model: Interactive visuals for identified topic clusters.\\n\")\n",
        "\n",
        "# Fit the BERTopic model to generate topics\n",
        "topic_model = BERTopic(min_topic_size=2)\n",
        "topic_clusters, probabilities = topic_model.fit_transform(reviews_data['content'])\n",
        "\n",
        "# Display the BERTopic Barchart\n",
        "print(\"BERTopic Top Words Barchart:\")\n",
        "barchart_fig = topic_model.visualize_barchart()\n",
        "barchart_fig.show()\n",
        "\n",
        "# Display the BERTopic Heatmap\n",
        "print(\"\\nBERTopic Topic Similarity Heatmap:\")\n",
        "heatmap_fig = topic_model.visualize_heatmap()\n",
        "heatmap_fig.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "1iriqtj9425G",
        "outputId": "fed453a1-fa69-4593-a588-be1935eae050"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LSA Model: Summarizing broader patterns and possible term overlap.\n",
            "\n",
            "LSA Topic 1:  ['coffee', 've', 'easy', 'constantly', 'terrible', 'day', 'battery', 'just', 'use', 'quality']\n",
            "LSA Topic 2:  ['owned', 'notch', 'features', 'far', 'coffee', 'love', 'tv', 'best', 've', 'easy']\n",
            "LSA Topic 3:  ['amazing', 'months', 'sound', 'disappointed', 'durability', 'headphones', 'use', 'just', 'stopped', 'working']\n",
            "\n",
            "BERTopic Model: Interactive visuals for identified topic clusters.\n",
            "\n",
            "BERTopic Top Words Barchart:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.35.2.min.js\"></script>                <div id=\"4df2fead-7d05-459c-b73a-5c28942064e5\" class=\"plotly-graph-div\" style=\"height:325.0px; width:1000px;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"4df2fead-7d05-459c-b73a-5c28942064e5\")) {                    Plotly.newPlot(                        \"4df2fead-7d05-459c-b73a-5c28942064e5\",                        [{\"marker\":{\"color\":\"#D55E00\"},\"orientation\":\"h\",\"x\":[0.07539070925508606,0.085678132005873,0.10281375840704761,0.10439345187529493,0.18495718045445572],\"y\":[\"this  \",\"it  \",\"is  \",\"and  \",\"the  \"],\"type\":\"bar\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"marker\":{\"color\":\"#0072B2\"},\"orientation\":\"h\",\"x\":[0.08215562695514615,0.08858381371714455,0.11350212739948941,0.11787472546183965,0.14608122969985396],\"y\":[\"easy  \",\"its  \",\"this  \",\"and  \",\"my  \"],\"type\":\"bar\",\"xaxis\":\"x2\",\"yaxis\":\"y2\"}],                        {\"template\":{\"data\":{\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"#C8D4E3\",\"linecolor\":\"#C8D4E3\",\"minorgridcolor\":\"#C8D4E3\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"#C8D4E3\",\"linecolor\":\"#C8D4E3\",\"minorgridcolor\":\"#C8D4E3\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"white\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"#C8D4E3\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"white\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\"},\"bgcolor\":\"white\",\"radialaxis\":{\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"},\"yaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"},\"zaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"},\"bgcolor\":\"white\",\"caxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#EBF0F8\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#EBF0F8\",\"zerolinewidth\":2}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,0.175],\"showgrid\":true},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"showgrid\":true},\"xaxis2\":{\"anchor\":\"y2\",\"domain\":[0.275,0.45],\"showgrid\":true},\"yaxis2\":{\"anchor\":\"x2\",\"domain\":[0.0,1.0],\"showgrid\":true},\"xaxis3\":{\"anchor\":\"y3\",\"domain\":[0.55,0.7250000000000001],\"showgrid\":true},\"yaxis3\":{\"anchor\":\"x3\",\"domain\":[0.0,1.0],\"showgrid\":true},\"xaxis4\":{\"anchor\":\"y4\",\"domain\":[0.825,1.0],\"showgrid\":true},\"yaxis4\":{\"anchor\":\"x4\",\"domain\":[0.0,1.0],\"showgrid\":true},\"annotations\":[{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"Topic 0\",\"x\":0.0875,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":1.0,\"yanchor\":\"bottom\",\"yref\":\"paper\"},{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"Topic 1\",\"x\":0.36250000000000004,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":1.0,\"yanchor\":\"bottom\",\"yref\":\"paper\"}],\"title\":{\"font\":{\"size\":22,\"color\":\"Black\"},\"text\":\"Topic Word Scores\",\"x\":0.5,\"xanchor\":\"center\",\"yanchor\":\"top\"},\"hoverlabel\":{\"font\":{\"size\":16,\"family\":\"Rockwell\"},\"bgcolor\":\"white\"},\"showlegend\":false,\"width\":1000,\"height\":325.0},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('4df2fead-7d05-459c-b73a-5c28942064e5');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "BERTopic Topic Similarity Heatmap:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.35.2.min.js\"></script>                <div id=\"3e5b949c-8f3e-4052-9987-4ca8d9a5b815\" class=\"plotly-graph-div\" style=\"height:800px; width:800px;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"3e5b949c-8f3e-4052-9987-4ca8d9a5b815\")) {                    Plotly.newPlot(                        \"3e5b949c-8f3e-4052-9987-4ca8d9a5b815\",                        [{\"coloraxis\":\"coloraxis\",\"name\":\"0\",\"x\":[\"0_the_and_is\",\"1_my_and_this\"],\"y\":[\"0_the_and_is\",\"1_my_and_this\"],\"z\":[[1.0,0.4521632790565491],[0.4521632790565491,0.9999997019767761]],\"type\":\"heatmap\",\"xaxis\":\"x\",\"yaxis\":\"y\",\"hovertemplate\":\"x: %{x}\\u003cbr\\u003ey: %{y}\\u003cbr\\u003eSimilarity Score: %{z}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"scaleanchor\":\"y\",\"constrain\":\"domain\"},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"autorange\":\"reversed\",\"constrain\":\"domain\"},\"coloraxis\":{\"colorbar\":{\"title\":{\"text\":\"Similarity Score\"}},\"colorscale\":[[0.0,\"rgb(247,252,240)\"],[0.125,\"rgb(224,243,219)\"],[0.25,\"rgb(204,235,197)\"],[0.375,\"rgb(168,221,181)\"],[0.5,\"rgb(123,204,196)\"],[0.625,\"rgb(78,179,211)\"],[0.75,\"rgb(43,140,190)\"],[0.875,\"rgb(8,104,172)\"],[1.0,\"rgb(8,64,129)\"]]},\"margin\":{\"t\":60},\"title\":{\"font\":{\"size\":22,\"color\":\"Black\"},\"text\":\"\\u003cb\\u003eSimilarity Matrix\\u003c\\u002fb\\u003e\",\"y\":0.95,\"x\":0.55,\"xanchor\":\"center\",\"yanchor\":\"top\"},\"hoverlabel\":{\"font\":{\"size\":16,\"family\":\"Rockwell\"},\"bgcolor\":\"white\"},\"width\":800,\"height\":800,\"showlegend\":true,\"legend\":{\"title\":{\"text\":\"Trend\"}}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('3e5b949c-8f3e-4052-9987-4ca8d9a5b815');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. **LSA Topic Terms**:\n",
        "   - This output shows the most important words for each topic identified by the LSA model. By examining these key terms, we can understand the general themes that LSA has extracted from the dataset. Note that some words may appear in multiple topics, which indicates that LSA is capturing broader patterns but might have overlapping themes among topics.\n",
        "\n",
        "2. **BERTopic Barchart**:\n",
        "   - The BERTopic barchart displays the top words for each topic, where the length of each bar reflects the significance of the word within that specific topic. This visualization helps in quickly identifying the primary terms associated with each topic, allowing us to grasp the central ideas that each cluster represents.\n",
        "\n",
        "3. **BERTopic Heatmap**:\n",
        "   - The heatmap from BERTopic illustrates the similarity between the topics. Topics that are closely related are positioned nearer to each other and exhibit warmer colors, indicating higher similarity. This visual makes it easy to identify which topics are interrelated, providing insights into the relationships between the generated topic clusters.\n"
      ],
      "metadata": {
        "id": "XF1fL8LQAvVY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Extra Question (5 Points)\n",
        "\n",
        "**Compare the results generated by the four topic modeling algorithms, which one is better? You should explain the reasons in details.**\n",
        "\n",
        "**This question will compensate for any points deducted in this exercise. Maximum marks for the exercise is 40 points.**"
      ],
      "metadata": {
        "id": "d89ODUx3jjJV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Write your code here\n",
        "import pandas as pd\n",
        "from sklearn.decomposition import TruncatedSVD\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from gensim.corpora import Dictionary\n",
        "from gensim.models import LdaModel\n",
        "from gensim.models.coherencemodel import CoherenceModel\n",
        "from bertopic import BERTopic\n",
        "\n",
        "# Sample dataset containing various reviews\n",
        "dataset = pd.DataFrame({\n",
        "    'review': [\n",
        "        \"I bought this phone two weeks ago, and I have been extremely satisfied with its performance. The battery lasts all day, and the camera quality is outstanding. Highly recommend!\",\n",
        "    \"Terrible laptop. It overheats constantly, and the battery dies in just a couple of hours. I regret purchasing this product.\",\n",
        "    \"This vacuum cleaner has made my life so much easier. It's lightweight, powerful, and very easy to maneuver. I love how clean my house feels after using it.\",\n",
        "    \"The sound quality of these headphones is amazing. However, after just two months, one side stopped working. I'm disappointed with the durability.\",\n",
        "    \"I’ve tried a lot of fitness trackers, and this one is by far the best. It’s comfortable to wear, the tracking is accurate, and I love the sleep monitoring feature.\",\n",
        "    \"This blender is a waste of money. It struggles with basic tasks like blending frozen fruit and constantly overheats. Definitely avoid this product.\",\n",
        "    \"Fantastic service! The customer support team was responsive and helped me resolve my issue quickly. I will continue to shop with this company.\",\n",
        "    \"The quality of this TV is top-notch. The picture is crystal clear, and the smart features are easy to use. It's the best TV I’ve ever owned.\",\n",
        "    \"Worst purchase ever. The shoes fell apart after just a few days of light use. Poorly made and not worth the money.\",\n",
        "    \"The camera takes great photos, but the app is clunky and hard to navigate. I would give it 5 stars for the camera, but the software brings it down to a 3.\",\n",
        "    \"I love this coffee maker. It’s quick, easy to use, and makes the best cup of coffee I’ve ever had at home. I can’t start my day without it.\",\n",
        "    \"The washing machine is too loud and doesn't clean clothes as well as my old one. It's not worth the high price tag.\",\n",
        "    \"The tablet is great for reading and light browsing, but it slows down when I try to use it for anything more demanding. Good for basic tasks, but not a powerful device.\",\n",
        "    \"I purchased this sofa for my living room, and it fits perfectly. The material feels durable, and it’s very comfortable to sit on. Highly satisfied with this purchase.\",\n",
        "    \"The smartwatch looks nice, but the battery life is terrible. It barely lasts through the day without needing a charge. I wouldn't recommend it.\",\n",
        "    \"This lawnmower works great for my small yard. It’s easy to push and cuts the grass evenly. I’m happy with my purchase so far.\",\n",
        "    \"The wireless mouse stopped working after just a week of use. I had higher expectations for this brand, but unfortunately, the quality is subpar.\",\n",
        "    \"I'm thrilled with my new gaming chair. It’s extremely comfortable, and the adjustable settings let me customize it to my preferences. Definitely worth the investment.\",\n",
        "    \"This printer is the worst. It constantly jams, the ink cartridges are expensive, and the print quality is terrible. Do not buy!\",\n",
        "    \"I’ve been using this air purifier for a month, and I can already notice a difference in the air quality. My allergies have improved, and it runs quietly in the background.\"\n",
        "    ]\n",
        "})\n",
        "\n",
        "# Perform basic preprocessing: lowercase text and tokenize\n",
        "dataset['cleaned'] = dataset['review'].apply(lambda x: x.lower())\n",
        "dataset['tokenized'] = dataset['cleaned'].apply(lambda x: x.split())\n",
        "\n",
        "# =================== 1. LDA Model with Coherence Score ===================\n",
        "print(\"LDA Model Analysis: Creating distinct topics with well-separated themes.\\n\")\n",
        "\n",
        "# Prepare LDA model input requirements\n",
        "review_dict = Dictionary(dataset['tokenized'])\n",
        "review_corpus = [review_dict.doc2bow(text) for text in dataset['tokenized']]\n",
        "\n",
        "# Run LDA model with 3 topics\n",
        "lda_analysis = LdaModel(review_corpus, num_topics=3, id2word=review_dict, random_state=100, passes=10)\n",
        "\n",
        "# Calculate coherence score for LDA topics\n",
        "lda_coherence_calc = CoherenceModel(model=lda_analysis, texts=dataset['tokenized'], dictionary=review_dict, coherence='c_v')\n",
        "lda_coherence_score = lda_coherence_calc.get_coherence()\n",
        "print(f\"LDA Model Coherence Score: {lda_coherence_score}\")\n",
        "\n",
        "# Show the top terms for each LDA topic\n",
        "lda_topic_terms = []\n",
        "for idx, topic in lda_analysis.show_topics(formatted=False):\n",
        "    lda_terms = [word for word, prob in topic]\n",
        "    lda_topic_terms.append(lda_terms)\n",
        "    print(f\"LDA Topic {idx + 1}: {lda_terms}\")\n",
        "print(\"\\n\")\n",
        "\n",
        "# =================== 2. LSA Model with Coherence Score ===================\n",
        "print(\"LSA Model Analysis: Highlighting broad patterns with possible overlapping terms.\\n\")\n",
        "\n",
        "# Apply TF-IDF vectorization\n",
        "tfidf_vectorizer = TfidfVectorizer(stop_words='english')\n",
        "X_matrix = tfidf_vectorizer.fit_transform(dataset['cleaned'])\n",
        "\n",
        "# Run LSA model with 3 topics\n",
        "n_topics = 3\n",
        "lsa_model = TruncatedSVD(n_components=n_topics, random_state=100)\n",
        "lsa_model.fit(X_matrix)\n",
        "\n",
        "# Gather top terms from each LSA topic for coherence scoring\n",
        "vocab_terms = tfidf_vectorizer.get_feature_names_out()\n",
        "lsa_topic_words = [[vocab_terms[i] for i in topic.argsort()[-10:]] for topic in lsa_model.components_]\n",
        "\n",
        "# Calculate coherence score for LSA topics\n",
        "lsa_coherence_calc = CoherenceModel(topics=lsa_topic_words, texts=dataset['tokenized'], dictionary=review_dict, coherence='c_v')\n",
        "lsa_coherence_score = lsa_coherence_calc.get_coherence()\n",
        "print(f\"LSA Model Coherence Score: {lsa_coherence_score}\")\n",
        "\n",
        "# Display top terms for each LSA topic\n",
        "for idx, topic in enumerate(lsa_model.components_):\n",
        "    print(f\"LSA Topic {idx + 1}: \", [vocab_terms[i] for i in topic.argsort()[-10:]])\n",
        "print(\"\\n\")\n",
        "\n",
        "# =================== 3. BERTopic Model ===================\n",
        "print(\"BERTopic Model Analysis: Clustered topics with flexibility for nuanced exploration.\\n\")\n",
        "\n",
        "# Run BERTopic model\n",
        "bertopic_instance = BERTopic(min_topic_size=2)\n",
        "topic_clusters, probabilities = bertopic_instance.fit_transform(dataset['review'])\n",
        "\n",
        "# Show the top terms for each BERTopic cluster\n",
        "bertopic_topic_words = bertopic_instance.get_topics()\n",
        "for idx, topic in bertopic_topic_words.items():\n",
        "    bertopic_terms = [word for word, prob in topic[:10]]\n",
        "    print(f\"BERTopic Topic {idx}: {bertopic_terms}\")\n",
        "print(\"\\n\")\n",
        "\n",
        "# =================== Summary of Model Performance ===================\n",
        "print(\"Summary of Model Comparisons:\\n\")\n",
        "\n",
        "# Display coherence scores for LDA and LSA models\n",
        "print(f\"LDA Coherence Score: {lda_coherence_score}\")\n",
        "print(f\"LSA Coherence Score: {lsa_coherence_score}\")\n",
        "print(\"\\nInterpretability Insights:\")\n",
        "\n",
        "# Determine which model offers the most coherent and interpretable results\n",
        "if lda_coherence_score > lsa_coherence_score:\n",
        "    print(\"LDA shows better separation and coherence between topics compared to LSA.\")\n",
        "else:\n",
        "    print(\"LSA captures broad thematic patterns and is effective for high-level analysis.\")\n",
        "\n",
        "# Additional notes on BERTopic's flexibility and interpretability\n",
        "print(\"While BERTopic does not calculate a coherence score, it provides highly interpretable clusters and useful visualizations, ideal for complex datasets.\")\n",
        "\n",
        "# Final model selection based on performance\n",
        "print(\"\\nFinal Perdict:\")\n",
        "if lda_coherence_score > lsa_coherence_score and lda_coherence_score > 0.4:\n",
        "    print(\"LDA is the recommended model for well-defined, distinct topics with high coherence.\")\n",
        "elif lsa_coherence_score > lda_coherence_score:\n",
        "    print(\"LSA is preferred for identifying broader themes, even if overlap between topics is acceptable.\")\n",
        "else:\n",
        "    print(\"BERTopic is optimal for datasets requiring nuanced topic interpretation and interactive visualizations.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TUOvwrWe9FTC",
        "outputId": "70670c61-decc-411a-93eb-b107e8fe78da"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning:\n",
            "\n",
            "`should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LDA Model Analysis: Creating distinct topics with well-separated themes.\n",
            "\n",
            "LDA Model Coherence Score: 0.221383092991048\n",
            "LDA Topic 1: ['and', 'this', 'i', 'for', 'it', 'the', 'of', 'to', 'my', 'a']\n",
            "LDA Topic 2: ['and', 'the', 'this', 'very', 'it', 'feels', 'i', 'a', 'made', 'for']\n",
            "LDA Topic 3: ['the', 'and', 'is', 'i', 'this', 'to', 'my', 'a', 'it', 'quality']\n",
            "\n",
            "\n",
            "LSA Model Analysis: Highlighting broad patterns with possible overlapping terms.\n",
            "\n",
            "LSA Model Coherence Score: 0.4590628174593488\n",
            "LSA Topic 1:  ['coffee', 've', 'easy', 'constantly', 'terrible', 'day', 'battery', 'just', 'use', 'quality']\n",
            "LSA Topic 2:  ['owned', 'notch', 'features', 'far', 'coffee', 'love', 'tv', 'best', 've', 'easy']\n",
            "LSA Topic 3:  ['amazing', 'months', 'sound', 'disappointed', 'durability', 'headphones', 'use', 'just', 'stopped', 'working']\n",
            "\n",
            "\n",
            "BERTopic Model Analysis: Clustered topics with flexibility for nuanced exploration.\n",
            "\n",
            "BERTopic Topic -1: ['this', 'with', 'and', 'perfectly', 'purchased', 'waste', 'material', 'living', 'like', 'room']\n",
            "BERTopic Topic 0: ['the', 'is', 'it', 'and', 'but', 'to', 'camera', 'for', 'its', 'extremely']\n",
            "BERTopic Topic 1: ['the', 'just', 'of', 'after', 'quality', 'is', 'this', 'working', 'worst', 'stopped']\n",
            "BERTopic Topic 2: ['my', 'and', 'its', 'easy', 'this', 'the', 'coffee', 'so', 'as', 'using']\n",
            "\n",
            "\n",
            "Summary of Model Comparisons:\n",
            "\n",
            "LDA Coherence Score: 0.221383092991048\n",
            "LSA Coherence Score: 0.4590628174593488\n",
            "\n",
            "Interpretability Insights:\n",
            "LSA captures broad thematic patterns and is effective for high-level analysis.\n",
            "While BERTopic does not calculate a coherence score, it provides highly interpretable clusters and useful visualizations, ideal for complex datasets.\n",
            "\n",
            "Final Perdict:\n",
            "LSA is preferred for identifying broader themes, even if overlap between topics is acceptable.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Mandatory Question"
      ],
      "metadata": {
        "id": "VEs-OoDEhTW4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Important: Reflective Feedback on this exercise**\n",
        "\n",
        "Please provide your thoughts and feedback on the exercises you completed in this assignment.\n",
        "\n",
        "Consider the following points in your response:\n",
        "\n",
        "**Learning Experience:** Describe your overall learning experience in working with text data and extracting features using various topic modeling algorithms. Did you understand these algorithms and did the implementations helped in grasping the nuances of feature extraction from text data.\n",
        "\n",
        "**Challenges Encountered:** Were there specific difficulties in completing this exercise?\n",
        "\n",
        "Relevance to Your Field of Study: How does this exercise relate to the field of NLP?\n",
        "\n",
        "**(Your submission will not be graded if this question is left unanswered)**\n",
        "\n"
      ],
      "metadata": {
        "id": "IUKC7suYhVl0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Your answer here (no code for this question, write down your answer as detail as possible for the above questions):\n",
        "\n",
        "'''\n",
        "This exercise provided a valuable learning experience in handling text data and applying different topic modeling algorithms to extract meaningful features.\n",
        "Working with LDA, LSA, and BERTopic allowed me to explore how each algorithm handles topic identification, and the hands-on implementation deepened my understanding of their strengths and limitations.\n",
        "I gained insight into the nuances of feature extraction, especially in balancing topic coherence and interpretability.\n",
        "A key challenge was understanding and configuring each model’s parameters to fit the data and produce clear topics, especially as each algorithm processes data differently.\n",
        "This exercise is highly relevant to the field of NLP, as topic modeling is foundational in organizing and analyzing vast text corpora, whether for sentiment analysis, summarization, or content classification in real-world applications.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "'''"
      ],
      "metadata": {
        "id": "CAq0DZWAhU9m",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 212
        },
        "outputId": "c8d66abd-4f01-4b7c-f718-0afc0475f24a"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning:\n",
            "\n",
            "`should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nThis exercise provided a valuable learning experience in handling text data and applying different topic modeling algorithms to extract meaningful features.\\nWorking with LDA, LSA, and BERTopic allowed me to explore how each algorithm handles topic identification, and the hands-on implementation deepened my understanding of their strengths and limitations. \\nI gained insight into the nuances of feature extraction, especially in balancing topic coherence and interpretability. \\nA key challenge was understanding and configuring each model’s parameters to fit the data and produce clear topics, especially as each algorithm processes data differently. \\nThis exercise is highly relevant to the field of NLP, as topic modeling is foundational in organizing and analyzing vast text corpora, whether for sentiment analysis, summarization, or content classification in real-world applications.\\n\\n\\n\\n\\n\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}